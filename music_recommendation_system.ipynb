{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T19:04:29.022416Z",
     "start_time": "2024-12-12T19:04:27.172926Z"
    }
   },
   "source": [
    "from pyexpat import features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f2afe30c02ceaddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:09.881798Z",
     "start_time": "2024-12-12T19:05:09.879819Z"
    }
   },
   "source": [
    "track_path = 'tracks.csv'\n",
    "playlist_path = 'playlists.csv'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "69dc4fce",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afe4e0",
   "metadata": {},
   "source": [
    "* Read `track.csv` file\n",
    "* drop unused columns\n",
    "* drop duplicate tracks based on `Track_ID` column"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7b4660371ee6244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:14.106222Z",
     "start_time": "2024-12-12T19:05:13.984008Z"
    }
   },
   "source": [
    "tracks = pd.read_csv(track_path)\n",
    "tracks = tracks.drop(['Unnamed: 0'], axis=1)\n",
    "tracks = tracks.drop_duplicates(subset=['Track_ID'])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "31868b7f",
   "metadata": {},
   "source": [
    "* Read `playlists.csv` file\n",
    "* drop unused columns\n",
    "* drop duplicate tracks in a playlists based on `pid` and `track_id` column"
   ]
  },
  {
   "cell_type": "code",
   "id": "e249a39c0a86c22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:18.472094Z",
     "start_time": "2024-12-12T19:05:18.269072Z"
    }
   },
   "source": [
    "playlists = pd.read_csv(playlist_path)\n",
    "playlists = playlists.drop(['Unnamed: 0', 'track_uri', 'album_uri', 'artist_uri'], axis=1)\n",
    "playlists = playlists.drop_duplicates(subset=['pid', 'track_id'])"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "f5a5f041",
   "metadata": {},
   "source": [
    "* Convert `Release Date` from string to datetime data type\n",
    "* Convert `Explicit` from boolean to integer data type"
   ]
  },
  {
   "cell_type": "code",
   "id": "54addcfee08125be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:19.885070Z",
     "start_time": "2024-12-12T19:05:19.872138Z"
    }
   },
   "source": [
    "tracks['Release Date'] = pd.to_datetime(tracks['Release Date'], format='%Y-%m-%d', errors='coerce')\n",
    "tracks['Explicit'] = tracks['Explicit'].astype(int)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "5eb2abf7",
   "metadata": {},
   "source": [
    "* Splits each playlist into train and test tracks by 80% and 20%"
   ]
  },
  {
   "cell_type": "code",
   "id": "6490364e88b23993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:21.769587Z",
     "start_time": "2024-12-12T19:05:21.616208Z"
    }
   },
   "source": [
    "def train_test_split_playlists(playlists, test_ratio=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits each playlist into train and test tracks. This simulates a scenario\n",
    "    where we know some subset of a user's playlist tracks (train) and want to \n",
    "    predict the missing ones (test).\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for pid, group in playlists.groupby('pid'):\n",
    "        track_list = group['track_id'].tolist()\n",
    "        np.random.shuffle(track_list)\n",
    "        split_index = int(len(track_list)*(1-test_ratio))\n",
    "        train_tracks = track_list[:split_index]\n",
    "        test_tracks = track_list[split_index:]\n",
    "        \n",
    "        for t in train_tracks:\n",
    "            train_data.append({'pid': pid, 'track_id': t})\n",
    "        for t in test_tracks:\n",
    "            test_data.append({'pid': pid, 'track_id': t})\n",
    "            \n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = train_test_split_playlists(playlists, test_ratio=0.2)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "200b6f20",
   "metadata": {},
   "source": [
    "* Normalize the numeric features by MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "id": "84b61cd454879fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:24.435411Z",
     "start_time": "2024-12-12T19:05:24.408399Z"
    }
   },
   "source": [
    "numeric_features = ['Popularity', 'Danceability', 'Energy', 'Loudness', 'Speechiness', \n",
    "                    'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Explicit']\n",
    "train_track_ids = train_df['track_id'].unique()\n",
    "train_tracks_df = tracks[tracks['Track_ID'].isin(train_track_ids)]\n",
    "scaler = MinMaxScaler()\n",
    "train_tracks_df.loc[:, numeric_features] = scaler.fit_transform(train_tracks_df[numeric_features].astype(float))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/l6763p1n6ml_4wk4cqxj_lqm0000gn/T/ipykernel_3688/463527593.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.18888889 ... 0.         0.         0.35555556]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_tracks_df.loc[:, numeric_features] = scaler.fit_transform(train_tracks_df[numeric_features].astype(float))\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac77ec769ca6c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:27:20.219794Z",
     "start_time": "2024-12-07T22:27:20.213615Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_scaled_values = scaler.transform(tracks[numeric_features])\n",
    "# tracks[numeric_features] = all_scaled_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a6185",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73efa471",
   "metadata": {},
   "source": [
    "* Get user's training tracks"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8240adc7c524177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:42.804646Z",
     "start_time": "2024-12-12T19:05:42.801766Z"
    }
   },
   "source": [
    "def get_user_playlist_tracks(playlist_df, pid):\n",
    "    user_playlist = playlist_df[playlist_df['pid'] == pid]\n",
    "    user_track_ids = user_playlist['track_id'].unique()\n",
    "    return user_playlist, user_track_ids"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "f8fefca1",
   "metadata": {},
   "source": [
    "* Build a user profile from the training tracks by averaging the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "id": "61128a28b48d0d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:45.816157Z",
     "start_time": "2024-12-12T19:05:45.812498Z"
    }
   },
   "source": [
    "def build_user_profile(tracks_df, user_track_ids, numeric_features):\n",
    "    user_tracks = tracks_df[tracks_df['Track_ID'].isin(user_track_ids)]\n",
    "    if user_tracks.empty:\n",
    "        return None\n",
    "    user_profile = user_tracks[numeric_features].mean(axis=0).values.reshape(1, -1)\n",
    "    return user_profile\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "75fa4007",
   "metadata": {},
   "source": [
    "* Compute content-based similarity scores for tracks not in the user's training set."
   ]
  },
  {
   "cell_type": "code",
   "id": "34d719e76fa0815c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:47.901293Z",
     "start_time": "2024-12-12T19:05:47.898489Z"
    }
   },
   "source": [
    "def compute_content_scores(tracks_df, user_profile, user_track_ids, numeric_features):\n",
    "    candidate_tracks = tracks_df[~tracks_df['Track_ID'].isin(user_track_ids)].copy()\n",
    "    if candidate_tracks.empty or user_profile is None:\n",
    "        return pd.DataFrame(columns=['Track_ID', 'content_score'])\n",
    "    \n",
    "    candidate_features = candidate_tracks[numeric_features].values\n",
    "    similarities = cosine_similarity(candidate_features, user_profile)\n",
    "    candidate_tracks['content_score'] = similarities[:, 0]\n",
    "    return candidate_tracks[['Track_ID', 'content_score']]"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "17d720fe",
   "metadata": {},
   "source": [
    "* Build a co-occurrence matrix from the training dataset. This prevents the model from \"seeing\" test co-occurrences."
   ]
  },
  {
   "cell_type": "code",
   "id": "72d82ca333888ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:05:54.337752Z",
     "start_time": "2024-12-12T19:05:54.331730Z"
    }
   },
   "source": [
    "def build_cooccurrence_df(playlist_df):\n",
    "    grouped = playlist_df.groupby('pid')['track_id'].apply(list)\n",
    "    records = []\n",
    "    for track_list in grouped:\n",
    "        for i in range(len(track_list)):\n",
    "            for j in range(i+1, len(track_list)):\n",
    "                t1, t2 = track_list[i], track_list[j]\n",
    "                records.append((t1, t2, 1))\n",
    "                records.append((t2, t1, 1))\n",
    "                \n",
    "    cooccurrence_df = pd.DataFrame(records, columns=['track_id_1', 'track_id_2', 'count'])\n",
    "    cooccurrence_df = cooccurrence_df.groupby(['track_id_1', 'track_id_2'], as_index=False)['count'].sum()\n",
    "    return cooccurrence_df"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "978e7a2827b7e3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:06:13.078080Z",
     "start_time": "2024-12-12T19:06:12.265341Z"
    }
   },
   "source": [
    "cooccurrence = build_cooccurrence_df(train_df)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T23:59:40.964683Z",
     "start_time": "2024-12-12T23:59:40.942152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_playlist, user_track_ids = get_user_playlist_tracks(train_df, 679430)\n",
    "\n",
    "user_profile = build_user_profile(train_tracks_df, user_track_ids, numeric_features)\n",
    "#np.set_printoptions(suppress=True)\n",
    "print(user_profile)\n",
    "print(numeric_features)"
   ],
   "id": "cde8b1b7d1f6da17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58888889 0.68036437 0.7018     0.84107911 0.12748958 0.2296247\n",
      "  0.00000593 0.16032032 0.50530777 0.48692648 0.7       ]]\n",
      "['Popularity', 'Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Explicit']\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:33:47.657053Z",
     "start_time": "2024-12-12T19:20:02.015373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#matrix = cooccurrence.pivot(index=\"track_id_1\", columns=\"track_id_2\", values=\"count\").fillna(0)\n",
    "#matrix_nonzero = matrix.replace(0, \"\")\n",
    "\n",
    "matrix = cooccurrence.pivot(index=\"track_id_1\", columns=\"track_id_2\", values=\"count\").fillna(0)\n",
    "matrix.to_csv(\"cooccurrence_matrix.csv\", index=True)\n",
    "\n",
    "\n",
    "#print(matrix_nonzero)"
   ],
   "id": "d9210025455943cc",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "5d7988b5",
   "metadata": {},
   "source": [
    "* Compute collaborative filtering scores from co-occurrence matrix for candidate tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2202a2762387d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:27:21.100306Z",
     "start_time": "2024-12-07T22:27:21.096917Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_collaborative_scores_df(user_track_ids, cooccurrence_df, all_track_ids):\n",
    "    user_cooccurrences = cooccurrence_df[cooccurrence_df['track_id_1'].isin(user_track_ids)]\n",
    "    user_cooccurrences = user_cooccurrences[~user_cooccurrences['track_id_2'].isin(user_track_ids)]\n",
    "    \n",
    "    collab_df = user_cooccurrences.groupby('track_id_2', as_index=False)['count'].sum()\n",
    "    collab_df.rename(columns={'track_id_2': 'Track_ID', 'count': 'collab_score'}, inplace=True)\n",
    "    \n",
    "    if not collab_df.empty:\n",
    "        collab_df['collab_score'] = collab_df['collab_score'] / collab_df['collab_score'].max()\n",
    "    else:\n",
    "        collab_df['collab_score'] = 0\n",
    "    \n",
    "    collab_df = collab_df[collab_df['Track_ID'].isin(all_track_ids)]\n",
    "    return collab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428911b",
   "metadata": {},
   "source": [
    "* Generate hybrid recommendations by both content-based filtering and collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437c20f99892fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:27:21.116572Z",
     "start_time": "2024-12-07T22:27:21.113138Z"
    }
   },
   "outputs": [],
   "source": [
    "def hybrid_recommendations(tracks_df, user_profile, user_track_ids, numeric_features, cooccurrence_df, top_n, alpha=0.5):\n",
    "    content_scores = compute_content_scores(tracks_df, user_profile, user_track_ids, numeric_features)\n",
    "    all_track_ids = set(tracks_df['Track_ID'].unique())\n",
    "    collab_scores = compute_collaborative_scores_df(user_track_ids, cooccurrence_df, all_track_ids)\n",
    "    \n",
    "    combined = pd.merge(content_scores, collab_scores, on='Track_ID', how='outer').fillna(0)\n",
    "    combined['hybrid_score'] = alpha * combined['content_score'] + (1 - alpha) * combined['collab_score']\n",
    "    combined = combined.sort_values('hybrid_score', ascending=False)\n",
    "    return combined.head(top_n)['Track_ID'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272596e",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a3b7c",
   "metadata": {},
   "source": [
    "* Evaluate the model by comparing the recommended tracks to the test tracks. We only use co-occurrence and user profiles built from training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ba6d6d8713759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:46:10.811957Z",
     "start_time": "2024-12-07T22:46:10.802298Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tracks_df, train_df, test_df, numeric_features, cooccurrence, alpha=0.5):\n",
    "    test_dict = test_df.groupby('pid')['track_id'].apply(set).to_dict()\n",
    "    train_dict = train_df.groupby('pid')['track_id'].apply(set).to_dict()\n",
    "    \n",
    "    precisions, recalls = [], []\n",
    "    results = []\n",
    "    for pid in train_df['pid'].unique():\n",
    "        user_train_tracks = train_dict.get(pid, set())\n",
    "        user_test_tracks = test_dict.get(pid, set())\n",
    "        \n",
    "        if len(user_test_tracks) == 0:\n",
    "            continue\n",
    "        total_playlist_size = len(user_train_tracks) + len(user_test_tracks)\n",
    "        \n",
    "        # Build user profile from train tracks only\n",
    "        user_profile = build_user_profile(tracks_df, list(user_train_tracks), numeric_features)\n",
    "        if user_profile is None:\n",
    "            continue\n",
    "        \n",
    "        recommendations = hybrid_recommendations(\n",
    "            tracks_df,\n",
    "            user_profile,\n",
    "            list(user_train_tracks),\n",
    "            numeric_features,\n",
    "            cooccurrence,\n",
    "            len(user_test_tracks),\n",
    "            alpha=alpha\n",
    "        )\n",
    "        \n",
    "        recommended_set = set(recommendations)\n",
    "        hit_count = len(recommended_set.intersection(user_train_tracks.union(user_test_tracks)))\n",
    "        \n",
    "        #print(f\"Length of test: {len(user_test_tracks)} | Length of recommendations: {len(recommended_set)}\")\n",
    "        #print(f\"Hit count: {hit_count}\")\n",
    "        \n",
    "        precision = hit_count / len(user_test_tracks)\n",
    "        recall = hit_count / len(user_test_tracks)\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        results.append({\n",
    "            'pid': pid,\n",
    "            'hit_rate': recall,\n",
    "            'playlist_length': total_playlist_size\n",
    "        })\n",
    "        \n",
    "    avg_precision = np.mean(precisions) if precisions else 0\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d778eb",
   "metadata": {},
   "source": [
    "* alpha = 1 - recommend tracks with only content-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6a3dd65988373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:15:04.899173Z",
     "start_time": "2024-12-07T23:06:28.040657Z"
    }
   },
   "outputs": [],
   "source": [
    "content_results_df = evaluate_model(tracks, train_df, test_df, numeric_features, cooccurrence, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d0bfdb7fdd18a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:15:10.889288Z",
     "start_time": "2024-12-07T23:15:10.886415Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_content_hit_rate = content_results_df['hit_rate'].mean()\n",
    "print(f\"Content-Based Filtering Hit Rate: {overall_content_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee2c2a",
   "metadata": {},
   "source": [
    "* alpha = 0, recommend tracks with only collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3515cf60b5da980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:23:13.113596Z",
     "start_time": "2024-12-07T23:15:14.426732Z"
    }
   },
   "outputs": [],
   "source": [
    "colab_results_df = evaluate_model(tracks, train_df, test_df, numeric_features, cooccurrence, alpha=0, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88535a3a0b47811c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:23:55.390338Z",
     "start_time": "2024-12-07T23:23:55.383551Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_colab_hit_rate = colab_results_df['hit_rate'].mean()\n",
    "print(f\"Collaborative Filtering Hit Rate: {overall_colab_hit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31e619d",
   "metadata": {},
   "source": [
    "* Find the optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = []\n",
    "mean_hit_rate = []\n",
    "\n",
    "for param in np.arange(0.1, 1.1, 0.01):\n",
    "    alpha.append(param)\n",
    "    print(param)\n",
    "    result_df = evaluate_model(tracks, train_df, test_df, numeric_features, cooccurrence, alpha=param)\n",
    "    hit_rate = result_df['hit_rate'].mean()\n",
    "    mean_hit_rate.append(hit_rate)\n",
    "    print(mean_hit_rate)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'alpha': alpha,\n",
    "    'mean_hit_rate': mean_hit_rate\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b29576",
   "metadata": {},
   "source": [
    "* Calculate the average hit rate for various sizes of playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119d03390a8245a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:54:57.160563Z",
     "start_time": "2024-12-07T22:46:14.678436Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = evaluate_model(tracks, train_df, test_df, numeric_features, cooccurrence, alpha=0.60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b4f28c77c3edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:58:44.133325Z",
     "start_time": "2024-12-07T22:58:44.126936Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_edges = [0, 5, 10, 15, 20, 25, 30, 35, 40]\n",
    "bin_labels = ['<5', '5-10', '11-15', '16-20', '21-25', '26-30', '31-35', '36-40']\n",
    "results_df['length_bin'] = pd.cut(results_df['playlist_length'], bins=bin_edges, labels=bin_labels, right=True)\n",
    "hit_rate_by_bin = results_df.groupby('length_bin', observed=False)['hit_rate'].mean().reset_index()\n",
    "\n",
    "# bin_counts = results_df['length_bin'].value_counts().reset_index()\n",
    "# bin_counts.columns = ['length_bin', 'playlist_count']\n",
    "\n",
    "print(hit_rate_by_bin)\n",
    "# print(bin_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff89b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "length_bin = [\"<5\", \"5-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-35\", \"36-40\"]\n",
    "hit_rate = [0.021277, 0.029343, 0.034079, 0.040047, 0.051994, 0.050600, 0.054314, 0.070072]\n",
    "\n",
    "# Create line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(length_bin, hit_rate, marker='o', linestyle='-', linewidth=2)\n",
    "plt.title(\"Hit Rate by Length Bin\", fontsize=16)\n",
    "plt.xlabel(\"Length Bin\", fontsize=14)\n",
    "plt.ylabel(\"Hit Rate\", fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6edc6d528bfc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
